{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b02765",
   "metadata": {},
   "source": [
    "# Общие методы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d3ff3b",
   "metadata": {},
   "source": [
    "## Все библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7ff3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import random\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torcheval.metrics as metrics\n",
    "from torch.utils.data.dataloader import DataLoader, Dataset  # Классы для простой работы с данными\n",
    "\n",
    "import skimage.io\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d888420a",
   "metadata": {},
   "source": [
    "## Фиксация сида рандомайзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9bd8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_seed(value=0):\n",
    "    random.seed(value)\n",
    "    np.random.seed(value)\n",
    "    torch.manual_seed(value)\n",
    "    torch.cuda.manual_seed(value)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a218b4",
   "metadata": {},
   "source": [
    "## Перенос данных на устройство обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbbfbdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data_to_device(data, device):\n",
    "    if torch.is_tensor(data):\n",
    "        return data.to(device)\n",
    "    elif isinstance(data, (list, tuple)):\n",
    "        return [copy_data_to_device(elem, device) for elem in data]\n",
    "    raise ValueError('Недопустимый тип данных {}'.format(type(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc690cc",
   "metadata": {},
   "source": [
    "## Печать статистику градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e24ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grad_stats(model):\n",
    "    mean = 0\n",
    "    std = 0\n",
    "    norm = 1e-5\n",
    "    for param in model.parameters():\n",
    "        grad = getattr(param, 'grad', None)\n",
    "        if grad is not None:\n",
    "            mean += grad.data.abs().mean()\n",
    "            std += grad.data.std()\n",
    "            norm += 1\n",
    "    mean /= norm\n",
    "    std /= norm\n",
    "    print(f'Mean grad {mean}, std {std}, n {norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22280b7",
   "metadata": {},
   "source": [
    "## Главная функция обучения и валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4814102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_loop(model, train_dataset, val_dataset, criterion,\n",
    "                    lr=1e-4, epoch_n=10, batch_size=32,\n",
    "                    device=None, early_stopping_patience=10, l2_reg_alpha=0,\n",
    "                    max_batches_per_epoch_train=10000,\n",
    "                    max_batches_per_epoch_val=1000,\n",
    "                    data_loader_ctor=DataLoader,\n",
    "                    optimizer_ctor=None,\n",
    "                    lr_scheduler_ctor=None,\n",
    "                    shuffle_train=True,\n",
    "                    dataloader_workers_n=0):\n",
    "    \"\"\"\n",
    "    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n",
    "    :param model: torch.nn.Module - обучаемая модель\n",
    "    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n",
    "    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n",
    "    :param criterion: функция потерь для настройки модели\n",
    "    :param lr: скорость обучения\n",
    "    :param epoch_n: максимальное количество эпох\n",
    "    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n",
    "    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n",
    "    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n",
    "        отсутствие улучшения модели, чтобы обучение продолжалось.\n",
    "    :param l2_reg_alpha: коэффициент L2-регуляризации\n",
    "    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n",
    "    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n",
    "    :param data_loader_ctor: функция для создания объекта, преобразующего датасет в батчи\n",
    "        (по умолчанию torch.utils.data.DataLoader)\n",
    "    :return: кортеж из двух элементов:\n",
    "        - среднее значение функции потерь на валидации на лучшей эпохе\n",
    "        - лучшая модель\n",
    "    \"\"\"\n",
    "    # Выбор устройства для обучения модели\n",
    "    if device is None:\n",
    "        device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "    model.to(device)\n",
    "\n",
    "    # Выбор оптимизатора\n",
    "    if optimizer_ctor is None:\n",
    "        # Если не выставлен, исползую Adam\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n",
    "    else:\n",
    "        # Иначе используй тот, что выставили\n",
    "        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n",
    "\n",
    "    # Выбор регулятора скорости обучения\n",
    "    if lr_scheduler_ctor is not None:\n",
    "        lr_scheduler = lr_scheduler_ctor(optimizer)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "\n",
    "    # Загрузка обучающего датасета\n",
    "    train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size, shuffle=shuffle_train,\n",
    "                                        num_workers=dataloader_workers_n)\n",
    "    # Загрузка валидационного датасета\n",
    "    val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                      num_workers=dataloader_workers_n)\n",
    "\n",
    "    # Инициализация переменных \"лучших\" значений потерь и \"лучшей\" эпохи и модели\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch_i = 0\n",
    "    best_model = copy.deepcopy(model)\n",
    "\n",
    "    # По каждой эпохе\n",
    "    for epoch_i in range(epoch_n):\n",
    "\n",
    "        try:\n",
    "            # Сохраняем время начала обучения эпохи\n",
    "            epoch_start = datetime.datetime.now()\n",
    "            print('Эпоха {}'.format(epoch_i))\n",
    "\n",
    "            # Режим обучения модели\n",
    "            model.train()\n",
    "            mean_train_loss = 0\n",
    "            train_batches_n = 0\n",
    "\n",
    "            # Для каждого батча данных\n",
    "            for batch_i, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "                # Если номер батча превысил количество батчей за эпоху, то завершаем\n",
    "                if batch_i > max_batches_per_epoch_train:\n",
    "                    break\n",
    "                \n",
    "                # Копируем батчи аргументов и ответов на устройство вычисления \n",
    "                batch_x = copy_data_to_device(batch_x, device)\n",
    "                batch_y = copy_data_to_device(batch_y, device)\n",
    "\n",
    "                # Создаем предсказание\n",
    "                pred = model(batch_x)\n",
    "\n",
    "                # Вычисляем отклонение\n",
    "                loss = criterion(pred, batch_y)\n",
    "\n",
    "                # Обнуляем градиент\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # Делаем шаг спуска\n",
    "                optimizer.step()\n",
    "\n",
    "                # Суммируем значения потери и считаем кол-во батчей\n",
    "                mean_train_loss += float(loss)\n",
    "                train_batches_n += 1\n",
    "            \n",
    "            # Считаем среднюю потерю за обучение\n",
    "            mean_train_loss /= train_batches_n\n",
    "\n",
    "            # Выводим информацию об эпохе\n",
    "\n",
    "            # print('Эпоха: {} итераций, {:0.2f} сек'.format(train_batches_n,\n",
    "            #                                                (datetime.datetime.now() - epoch_start).total_seconds()))\n",
    "            print(f'Эпоха: {train_batches_n} итераций, {(datetime.datetime.now() - epoch_start).total_seconds():0.2f} сек')\n",
    "            print(f'Среднее значение функции потерь на обучении {mean_train_loss}')\n",
    "\n",
    "            # Режим валидации модели\n",
    "            model.eval()\n",
    "            mean_val_loss = 0\n",
    "            val_batches_n = 0\n",
    "\n",
    "            # С отключенным вычислением градиента\n",
    "            with torch.no_grad():\n",
    "                # Для каждого батча валидации \n",
    "                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n",
    "                    if batch_i > max_batches_per_epoch_val:\n",
    "                        break\n",
    "                    \n",
    "                    # Копируем батчи аргументов и ответов на устройство вычисления                     \n",
    "                    batch_x = copy_data_to_device(batch_x, device)\n",
    "                    batch_y = copy_data_to_device(batch_y, device)\n",
    "\n",
    "                    # Создаем предсказание\n",
    "                    pred = model(batch_x)\n",
    "    \n",
    "                    # Вычисляем отклонение\n",
    "                    loss = criterion(pred, batch_y)\n",
    "\n",
    "                    # Суммируем значения потери и считаем кол-во батчей\n",
    "                    mean_val_loss += float(loss)\n",
    "                    val_batches_n += 1\n",
    "\n",
    "            # Считаем среднюю потерю за обучение\n",
    "            mean_val_loss /= val_batches_n\n",
    "            print(f'Среднее значение функции потерь на валидации {mean_val_loss}')\n",
    "\n",
    "            # Если средняя потеря валидации меньше лучшей\n",
    "            if mean_val_loss < best_val_loss:\n",
    "                # То сохраняем номер эпохи\n",
    "                best_epoch_i = epoch_i\n",
    "                # То значение потери\n",
    "                best_val_loss = mean_val_loss\n",
    "                # То сохраняем модель\n",
    "                best_model = copy.deepcopy(model)\n",
    "                print('Новая лучшая модель!')\n",
    "            # Иначе если модель не улучшилась через несколько эпох\n",
    "            elif epoch_i - best_epoch_i > early_stopping_patience:\n",
    "                print(f'Модель не улучшилась за последние {early_stopping_patience} эпох, прекращаем обучение')\n",
    "                # То останвливаем обучение\n",
    "                break\n",
    "            # Для существующего регулятора скорости обучения\n",
    "            if lr_scheduler is not None:\n",
    "                # Регулируем скорость\n",
    "                lr_scheduler.step(mean_val_loss)\n",
    "            print()\n",
    "        except KeyboardInterrupt:\n",
    "            print('Досрочно остановлено пользователем')\n",
    "            break\n",
    "        except Exception as ex:\n",
    "            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n",
    "            break\n",
    "\n",
    "    return best_val_loss, best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab26cd1b",
   "metadata": {},
   "source": [
    "## Вывод предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "905c00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_model(model, dataset, device=None, batch_size=32, num_workers=0, return_labels=False):\n",
    "    \"\"\"\n",
    "    :param model: torch.nn.Module - обученная модель\n",
    "    :param dataset: torch.utils.data.Dataset - данные для применения модели\n",
    "    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n",
    "    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n",
    "    :return: numpy.array размерности len(dataset) x *\n",
    "    \"\"\"\n",
    "    # Определяем устройство\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Инициализируем результаты батчей\n",
    "    results_by_batch = []\n",
    "\n",
    "    device = torch.device(device)\n",
    "    # Загружаем модель на устройство\n",
    "    model.to(device)\n",
    "    # И переводим в режим валидации\n",
    "    model.eval()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    labels = []\n",
    "\n",
    "    # С отключенным вычислением градиента\n",
    "    with torch.no_grad():\n",
    "        import tqdm\n",
    "        # Для каждого батча\n",
    "        for batch_x, batch_y in tqdm.tqdm(dataloader, total=len(dataset)/batch_size):\n",
    "            \n",
    "            # Копируем батч на устройство\n",
    "            batch_x = copy_data_to_device(batch_x, device)\n",
    "\n",
    "            # Если нужно вернуть названия классов\n",
    "            if return_labels:\n",
    "                labels.append(batch_y.numpy())\n",
    "\n",
    "            # Делаем предсказание\n",
    "            batch_pred = model(batch_x)\n",
    "\n",
    "            # Добавляем результаты в массив\n",
    "            results_by_batch.append(batch_pred.detach().cpu().numpy())\n",
    "    # Если нужно вернуть названия классов\n",
    "    if return_labels:\n",
    "        return np.concatenate(results_by_batch, 0), np.concatenate(labels, 0)\n",
    "    else:\n",
    "        return np.concatenate(results_by_batch, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a31fe",
   "metadata": {},
   "source": [
    "# Класс датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb23d9",
   "metadata": {},
   "source": [
    "## Загрузка датасета из kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18afbf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kagglehub\n",
    "# !kaggle config set -n path -v /home/nikosolov/Documents/SamsungMachineLearning/datasets\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"datamunge/sign-language-mnist\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f6cec5",
   "metadata": {},
   "source": [
    "## Создание трансформера изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a764acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms  = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.RandomVerticalFlip(p=0.25),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[-0.0932, -0.0971, -0.1260], std=[0.5091, 0.4912, 0.4931])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d886c99c",
   "metadata": {},
   "source": [
    "## Загрузка изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc471797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучающие данные\n",
    "train_data = torchvision.datasets.ImageFolder(\n",
    "    root='/kaggle/input/sports-classification/train', \n",
    "    transform=img_transforms\n",
    ")\n",
    "# Валидационные данные\n",
    "validation_data = torchvision.datasets.ImageFolder(\n",
    "    root='/kaggle/input/sports-classification/valid', \n",
    "    transform=img_transforms\n",
    ")\n",
    "# Тестирующие данные\n",
    "test_data = torchvision.datasets.ImageFolder(\n",
    "    root='/kaggle/input/sports-classification/test', \n",
    "    transform=img_transforms\n",
    ")\n",
    "\n",
    "len(train_data), len(validation_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a3e61",
   "metadata": {},
   "source": [
    "## Загрузка данных с изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae87ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_data, \n",
    "    batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=validation_data, \n",
    "    batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data, \n",
    "    batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "len(train_dataloader), len(validation_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524491e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем класс Датасета\n",
    "class MNISTdataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        # Загрузка датасета из файла по пути\n",
    "        self.dataset = pd.read_csv(file_path)\n",
    "        # Создание датасет классов к изображениям\n",
    "        self.classes_outcome = pd.DataFrame(\n",
    "            data = np.stack(\n",
    "                [np.arange(len(self.dataset)), self.dataset.iloc[:, 0].to_numpy()]\n",
    "                ).T, \n",
    "            columns = [\"Id\", \"Class\"])\n",
    "        # Создание трансформера изображения в изображение PIL и в тензор\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.ToPILImage(), transforms.ToTensor()]\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Получение размера датасета\n",
    "        return len(self.classes_outcome)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Получение элемента датасета\n",
    "        label = torch.tensor(int(self.classes_outcome.iloc[index, 1]))\n",
    "        image = torch.tensor(self.dataset.iloc[index, 1:].to_numpy(), dtype=torch.float32).reshape((1, 28, 28))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return [image, label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df5326",
   "metadata": {},
   "source": [
    "# Создание класса модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae8d899",
   "metadata": {},
   "source": [
    "## Загрузка предобученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee08a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предобученной модели ResNet\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# # Замена последнего слоя\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, 100)\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc9580",
   "metadata": {},
   "source": [
    "## Пример сверточной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe81f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание классификационной нейронной сети\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    # Конструктор класса ( 25 классов букв )\n",
    "    def __init__(self, num_classes=25):\n",
    "        super(CNN, self).__init__()\n",
    "        # Состовляем сверточные слои нейронки\n",
    "        self.conv_sequential = nn.Sequential(\n",
    "            # | 1 x 28 x 28\n",
    "            # Cлой свертки для 1 изображения с размером ядра 3 и паддингом 1 в 32 новых изображения\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            # Слой нормализации значений\n",
    "            nn.BatchNorm2d(32),\n",
    "            # Слой функции активации\n",
    "            nn.ReLU(),\n",
    "            # Макс пул для уменьшения изображения. Ядро 2 и stride 2, т.е. изображение уменьшится в 2 раза по сторонам\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # | 32 x 14 x 14\n",
    "\n",
    "            # Слои свертки для 32 изображений с размером ядра 3 и паддингом 1 в 64 новых изображения\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            # Слой нормализации\n",
    "            nn.BatchNorm2d(64),\n",
    "            # Слой активации\n",
    "            nn.ReLU(),\n",
    "            # Слой макс пула для уменьшения изображения. Ядро 2 и stride 2, т.е. изображение уменьшится в 2 раза по сторонам\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # | 64 x 7 x 7\n",
    "\n",
    "            # Слои свертки для 64 изображений с размером ядра 3 и паддингом 1 в 128 новых изображения\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            # Слой нормализации\n",
    "            nn.BatchNorm2d(128),\n",
    "            # Слой активации\n",
    "            nn.ReLU()\n",
    "            # | 128 x 7 x 7\n",
    "        )\n",
    "\n",
    "        # Состовляем линейные слои нейронки\n",
    "        self.linear_sequential = nn.Sequential(\n",
    "            # | Регуляризация\n",
    "            # Зануление половины значений\n",
    "            nn.Dropout(0.5),\n",
    "            # | 128 * 7 * 7\n",
    "            # Слой линейных нейронов 128*7*7 в 512\n",
    "            nn.Linear(128 * 7 * 7, 512),\n",
    "            # Слой активации\n",
    "            nn.ReLU(),\n",
    "            # | 512\n",
    "            # Слой линейных нейронов 512 в кол-во классов (25)\n",
    "            nn.Linear(512, num_classes)\n",
    "            # | nc\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_sequential(x)\n",
    "        # Преобразуем тензор для полносвязного слоя\n",
    "        x = x.view(-1, 128 * 7 * 7)\n",
    "        x = self.linear_sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03b9fe",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8856be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_loop(\n",
    "    model=CNN(num_classes=25), \n",
    "    train_dataset=train_dataset, \n",
    "    val_dataset=test_dataset, \n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    lr=1e-4, \n",
    "    epoch_n=20, \n",
    "    batch_size=2000,\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\", \n",
    "    early_stopping_patience=8, \n",
    "    l2_reg_alpha=0,\n",
    "    max_batches_per_epoch_train=10000,\n",
    "    max_batches_per_epoch_val=1000,\n",
    "    data_loader_ctor=DataLoader,\n",
    "    optimizer_ctor=None,\n",
    "    lr_scheduler_ctor=None,\n",
    "    shuffle_train=True,\n",
    "    dataloader_workers_n=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b6552a",
   "metadata": {},
   "source": [
    "# Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44a6c5c",
   "metadata": {},
   "source": [
    "# Сохранение и загрузка модели без прописывания класса модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5088044",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Сохранение модели\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Сохранение модели\n",
    "torch.jit.script(model).save('model_scripted.pt')\n",
    "# Загрузка модели без прописывания класса модели\n",
    "model = torch.jit.load('model_scripted.pt').eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
